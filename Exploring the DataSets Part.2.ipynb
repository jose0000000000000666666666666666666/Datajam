{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Exploration Part. 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAH Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, country, address, coordinates, \n",
    "                 location_type, trafficking_type, trafficking_sub_type,\n",
    "                 control_method, transportation_method, \n",
    "                 url_source_article, \n",
    "                ):\n",
    "        \n",
    "        self.country = self.format_text(country) \n",
    "        self.address = self.format_text(address)\n",
    "        self.coordinates = self.format_text(coordinates)\n",
    "        self.location_type = self.format_text(location_type)\n",
    "        self.trafficking_type = self.format_text(trafficking_type)\n",
    "        self.trafficking_sub_type = self.format_text(trafficking_sub_type)\n",
    "        self.control_method = self.format_text(control_method)\n",
    "        self.url_source_article = self.format_text(url_source_article)\n",
    "        \n",
    "    def format_text(self, text): \n",
    "        if text == \"nan\" or text == None: \n",
    "            return None\n",
    "        text = str(text).lower()\n",
    "        text = text.replace(\" \", \"_\")\n",
    "        return text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = \"./datasets/TAH/TAH-Classified_Bolivia_Colombia_Peru_Ecuador_Mexico.xlsx\"\n",
    "sheet_names = [\"Bolivia\", \"Colombia\", \"Peru\", \"Ecuador\", \"Mexico\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Country\", \"Coordinates\", \"Location Type\", \"Trafficking Type\", \n",
    "           \"Trafficking Sub-Type\", \"Control Method\", \n",
    "           \"Transportation Method\", \"URL Source Article\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in sheet_names: \n",
    "    data = pd.read_excel(filePath, sheet_name = name)\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        row = data[columns].iloc[i]\n",
    "\n",
    "        country = row[\"Country\"]\n",
    "        address = None\n",
    "        image = None\n",
    "        coordinates = row[\"Coordinates\"]\n",
    "        location_type = row[\"Location Type\"]\n",
    "        trafficking_type = row[\"Trafficking Type\"]\n",
    "        trafficking_sub_type = row[\"Trafficking Sub-Type\"]\n",
    "        control_method = row[\"Control Method\"]\n",
    "        transportation_method = row[\"Transportation Method\"]\n",
    "        url_source_article = row[\"URL Source Article\"]\n",
    "\n",
    "        # Instanciate vertex.\n",
    "        vertex = Node(\n",
    "            country, \n",
    "            address, \n",
    "            coordinates, \n",
    "            location_type, \n",
    "            trafficking_type, \n",
    "            trafficking_sub_type,\n",
    "            control_method, \n",
    "            transportation_method, \n",
    "            url_source_article\n",
    "        )\n",
    "\n",
    "        G.add_node(vertex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folium Map.\n",
    "import folium\n",
    "m = folium.Map(\n",
    "    location = [4.694821, -74.067305], \n",
    "    zoom_start = 12, \n",
    "    tiles = \"Stamen Terrain\"\n",
    ")\n",
    "\n",
    "list_coords = list()\n",
    "\n",
    "for node in G.nodes: \n",
    "    coords = node.coordinates.split(\",\")\n",
    "    coords[0] = float(coords[0])\n",
    "    coords[1] = float(coords[1])\n",
    "    \n",
    "    if [coords, node.trafficking_type] not in list_coords:\n",
    "        list_coords.append([coords, node.trafficking_type])    \n",
    "        marker = folium.Marker(\n",
    "            location = coords, \n",
    "            popup = node.trafficking_type,\n",
    "            icon = folium.Icon(color = \"red\")\n",
    "        )\n",
    "        marker.add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"index.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
